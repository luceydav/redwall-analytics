---
title: A Blueprint of "Red Flag" alerts Using Adjusted Earnings Data
author: David Lucey
date: '2021-04-21'
slug: a-blueprint-of-red-flag-alerts-using-adjusted-earnings-data
categories:
tags:
  - XBRL
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<div class="figure">
<img src="images/biblioteca-valenciana-nicolau-primitiu-QOPkIw4e52k-unsplash.jpg" width="600" alt="" />
<p class="caption">Photo by &lt;a href=“[<a href="https://unsplash.com/\\\@biblioteca_valenciana?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText%22\\" class="uri">https://unsplash.com/\\\@biblioteca_valenciana?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"\\</a>](<a href="https://unsplash.com/\@biblioteca_valenciana?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText%22\" class="uri">https://unsplash.com/\@biblioteca_valenciana?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText%22\</a>){.uri}&gt;Biblioteca Valenciana Nicolau Primitiu&lt;/a&gt; on &lt;a href=”[<a href="https://unsplash.com/s/photos/blimp?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText%22\\" class="uri">https://unsplash.com/s/photos/blimp?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText"\\</a>](<a href="https://unsplash.com/s/photos/blimp?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText%22\" class="uri">https://unsplash.com/s/photos/blimp?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText%22\</a>){.uri}&gt;Unsplash&lt;/a&gt;</p>
</div>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>In <a href="https://redwallanalytics.com/2020/02/18/a-walk-though-of-accessing-financial-statements-with-xbrl-in-r-part-1/">A Walk Though of Accessing Financial Statements with XBRL in R - Part 1</a> and <a href="https://redwallanalytics.com/2020/09/10/learning-sql-and-exploring-xbrl-with-secdatabase-com-part-1/">Learning SQL and Exploring XBRL with secdatabase.com - Part 1</a>, we set out with the hope of building a model to mine for “red flags” in financial statements following a roadmap set out in by Bruce Gulliver in the 2003 AIMR Conference Proceedings <a href="https://www.tandfonline.com/toc/ufaj20/current">Revelations in Financial Reporting</a>. Unfortunately, this paper is still behind a pay wall, but it is one of the most valuable research publications we have seen from the CFA Institute. We wish it were in the public domain after almost 20 years. Mr Gulliver used a similar methodology at his firm Jefferson Research to generate <a href="http://www.quantpartners.com/research/jefferson/concept.html">“Torpedo Alerts”</a>. We don’t know the status of his work more recently, but he could not be reached and the Jefferson Research website appears to no longer to be live. Our thanks for the way he synthesized and shared his research in a simple and understandable framework, and all the credit for the blueprint we are about to lay out here, goes to him.</p>
<p>While both of the previous posts mentioned above started out with ambitious intentions, neither could be completed with the available machine readable financial statement data. As reported, aggregated raw XBRL of many companies and periods didn’t allow for meaningful comparisons even with a company’s own past reports, because of changing tags over time. Comparisons with close competitors and those in other industries, are also complicated because of the leeway which companies have to customize reporting tags under XBRL rules. Finally, raw reported XBRL doesn’t offer ready tools to adjust the income statement for items in the MD&amp;A and footnotes in the way we would like. We were probably naive to hope for this, though we can still wish for a full open data set of the clean quarterly financial statements of all public companies, and all the adjustments for upload into analytic software environment like Python or R with the click of a mouse (like we have been able to do with so many other important open source data sets).</p>
<p>Though contrary to our goal to stick with mainly open source data in this blog, we concluded that we may have to explore commercial sources. We recently learned that <a href="https://www.newconstructs.com">New Constructs</a> (NC) has built a perfect data set for this purpose, which we will discuss in the next section. We were able to access New Constructs’ website to explore stock-by-stock data within their UI, but not to mine the full set of data as a whole in R. Please do not read on if expecting to see a completed study or code in R, but our intention is to pass on our findings and lay out a blueprint of what long-term forensic accounting “red flag” analysis might look like for others in the future.</p>
</div>
<div id="new-constructs" class="section level1">
<h1>New Constructs</h1>
<p>Last month, we learned of NC from their joint paper <a href="https://www.newconstructs.com/wp-content/uploads/2021/03/Investment-Industry-Opinion-Paper-Distribution-Is-Not-Enough.pdf">Distribution Is Not Enough</a>. Having operated since 2003, the accounting research firm had gradually built an impressive process combining man and machine, which has enabled them to scale up and reduce errors, which normally might be expected when conducting financial analysis on so many companies. This data set is in a different league from what we had seen with SEC Edgar, Financial Modeling Prep or SECDatabase.com. NC has gone through every earnings report since the late 1990s and adjusted annual 10-K’s for items left off the face of the balance sheets and income statements, but included in the MD&amp;A, footnotes and cash flow statements. They also have similarly adjusted quarterly data since 2013. We would advise anybody looking to learn about this topic to read their <a href="https://www.newconstructs.com/education/">Learn From Value-Investing Experts</a>, and particularly the section about “Accounting Fixes”, it is like a textbook on its own. They also offer many excellent webinars on the subject.</p>
<p>A team of Harvard and MIT researchers who had access to NC’s data recently published <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3467814">Core Earnings: New Data and Evidence</a> in the Journal of Financial Economics verifying the accuracy in a sample of reports and comparing the overall quality to Compustat. Though there are armies of analysts pouring over financial statements, they also demonstrating that NC’s adjustments were not really discounted by the market (finding an 8% excess return in back tests when comparing the companies with the most to the least adjustments). By the researchers count, NC found that approximately 30% of non-core items or almost 20% of net earnings over the period where non-core items dispersed throughout the 10-K, on and off the face of the income statement. They estimated that roughly half of these items on average were off the income statement (certainly a material amount), and found that the quantity and magnitude of such items had been increasing over time. The researchers found that NC’s core earnings had a significantly higher year-to-year persistence (ie: future earnings were more highly correlated with past periods once non-recurring items had been removed), and hence represent a better baseline in any model.</p>
<p>Mr. Gulliver never outlined how he cleaned his data although he did mention a service called Simplystocks, which was purchased by S&amp;P Global Intelligence in 2003. The main comparison used in the Harvard/MIT paper were with Compustat. In this post, we will outline the model we built as if we would be able to back test Mr. Gulliver’s “red flags” (using NC’s superior data). We found that the NC’s variables as shown in their <a href="https://client.newconstructs.com/nc/documentation/data-feed.htm">Data Feeds &amp; Dictionaries</a>. Without the access to the data, we thought of dropping the post, but having spent the time to do the research, we wanted to share the ideas and information with others who might have greater resources than ours. This post will be a walk-through of what a process like this would look like in hopes we one day get access to similar data.</p>
</div>
<div id="the-forgotten-art-of-forensic-accounting" class="section level1">
<h1>The Forgotten Art of Forensic Accounting</h1>
<p>In the best of circumstances, it has been challenging predicting winners and losers with the rise of the digital economy using reported GAAP metrics. Still, we believe that financial reporting remains a vital, although incomplete component of an investor’s toolkit. Just to cite some of the sources that we used to prepare for this project (aside from “Revelations in Financial Reporting”). Mr. Gulliver himself recommended <a href="https://www.amazon.com/Quality-Earnings-Thornton-L-Oglove/dp/0684863758">Quality of Earnings</a> by Thornton O’Glove (1987) and <a href="https://www.amazon.com/Financial-Warnings-Implementing-Corrective-Strategies/dp/0471120448">Financial Warnings: Detecting Earnings Surprises, Avoiding Business Troubles and Implementing Corrective Strategies</a> by Charles W. Mulford and Eugene E. Comiskey (1996). We also purchased Mulford &amp; Comiskey’s <a href="https://www.amazon.com/Financial-Numbers-Game-Detecting-Accounting/dp/0471770736">The Financial Numbers Game: Detecting Creative Accounting Practices</a> (2002) in our research.</p>
<p><a href="https://www.connectedpapers.com/main/d6861aa68adfc861fafa2a90c51771d6e7fce6f7/The-Financial-Numbers-Game-Detecting-Creative-Accounting-Practices/graph"><img src="images/Screen%20Shot%202021-04-29%20at%2012.03.43%20PM.png" title="Mulford&#39;s &quot;Financial Numbers Game&quot; a lonely academic endeavor" alt="Source: Connected Papers" /></a></p>
<p>The most recent of these sources is almost 20 years old at a time when arguably it should be most relevant (more than a decade into an historic bull market). When we look at it in this fantastic new tool called <a href="https://www.connectedpapers.com/main/d6861aa68adfc861fafa2a90c51771d6e7fce6f7/The-Financial-Numbers-Game-Detecting-Creative-Accounting-Practices/graph">Connected Papers</a>, we see that Mulford’s work stands completely on its own with no connections and among other ancient papers. We could speculate about why this approach to investing feels so out of favor at a time when data mining would seem to be at the top of mind. In the current environment, as seen after other extended bull markets, there is the feeling that people are more willing to invest in concepts and with less concern for future cash generation. But, this trend has been increasing for more than two decades, even prior to the GFC. It could be a bubble, but it also correspond with the shift of firm’s investment spending from fixed and measurable to internally-generated intangible assets as the Sparkline Capital below shows this clearly. In a future post, we will explore this possibility at greater length.</p>
<p><img src="images/Screen%20Shot%202021-04-23%20at%205.17.09%20PM.png" /></p>
<p>We would have guessed that the rise of free analytic software and machine readable data like XBRL would have led to a revolution in financial statement sleuthing, but we were wrong. <a href="https://www.connectedpapers.com/main/04422906f2bd9a718221f91867e037a732fe849f/Core-Earnings-New-Data-and-Evidence/graph">Core Earnings: New Data and Evidence</a> is also a lonely paper, although there are a few more recent papers which are similar.</p>
</div>
<div id="key-accounting-diseases" class="section level1">
<h1>Key Accounting Diseases</h1>
<p>For this post, we will stick to the goal of possibility of mining the full financial statement corpus for “red flags”. Mr. Gulliver gives four categories for diagnosing what he calls the “diseases”:</p>
<ul>
<li>Cash Flow Quality</li>
<li>Earnings Quality</li>
<li>Efficiency of Operations</li>
<li>Balance Sheet Quality (Liquidity)</li>
</ul>
<p>In his <a href="http://www.quantpartners.com/research/jefferson/concept.html">“<em>Torpedo Alerts</em>”</a> research, he also added a final screen for valuation. Within these larger categories, he often offers several sub-category, which we outline below. We will choose variables from NC’s website which we thought would best replicate these filters. The other key consideration is how to calculate and weight the “red flags”, because some must be more significant than others. As far as we can tell, Mr. Gulliver used equal-weighting, but with the data loaded up in an analytic software tool like R and Python, we would be able to iterate and even let a model tell us the most meaningful coefficients in predicting earnings warnings and/or significant stock price adjustment.</p>
<p>We would also be able to generate more complicated variables. Mr. Gulliver appeared to mainly use single year-on-year changes, but we would try out increasing the weight of persistent negative year-over-year changes over several years. Also, Mr. Gulliver did his analysis using quarterly data, but NC’s has only annual data before 2013, so we would have to mine for bigger disappointments if we wanted to use the longer time periods.</p>
<div id="cash-flow-quality" class="section level2">
<h2>CASH FLOW Quality</h2>
<p>Mr. Gulliver argues that an increasing gap between reported and adjusted cash flow is an indicator of poor cash flow quality. We would compare the trend in reported Operating Cash Flow with NC’s Free Cash Flow giving a penalty for the difference as it grows sequentially over reporting periods. His <em>Torpedo</em> methodology also compares Operating Cash Flow to Current Liabilities. We had not seen that as a significant factor, so perhaps we would consider giving this a lower weighting in the overall measure.</p>
<table>
<colgroup>
<col width="29%" />
<col width="30%" />
<col width="40%" />
</colgroup>
<thead>
<tr class="header">
<th>Torpedo</th>
<th>NC Ticker</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Op/Free Cash Flow</td>
<td>CASH_FLOW_OPERATING</td>
<td>Supporting CF - OpCF/FCF</td>
</tr>
<tr class="even">
<td>Op/Free Cash Flow</td>
<td>FREE_CASH_FLOW</td>
<td>NC version of FCF</td>
</tr>
<tr class="odd">
<td>Flow Ratio</td>
<td>CASH_FLOW_OPERATING</td>
<td>Operating CF/Current Liab.</td>
</tr>
<tr class="even">
<td>Flow Ratio</td>
<td>LIABILITIES_CURRENT</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div id="earnings-quality" class="section level2">
<h2>EARNINGS QUALITY</h2>
<div id="ar-inventory-balance-sheet" class="section level3">
<h3>A/R &amp; Inventory (Balance Sheet)</h3>
<p>The change in Inventory or Receivable levels relative to revenue run rates can be early indicators of changing interest in a company’s product or services. We propose to use a 3-year weighted average, with a growing penalty if the trend in Days continues to deteriorate year-on-year for more than one period.</p>
<table>
<colgroup>
<col width="19%" />
<col width="55%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th>Torpedo</th>
<th>NC Ticker</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Inventory</td>
<td>DAYS_IN_INVENTORY</td>
<td>Weighted change</td>
</tr>
<tr class="even">
<td>Receivables</td>
<td>DAYS_IN_REVENUE_OUTSTANDING</td>
<td>Weighted change</td>
</tr>
</tbody>
</table>
</div>
<div id="accruals-balance-sheet" class="section level3">
<h3>Accruals (Balance Sheet)</h3>
<p>Similar to Inventory and Sales Days Outstanding, the overall change in Reserves per change in revenue could be an early indicator of a change in operating conditions as a company reaches to meet expectations with less conservative assumptions. The NC RESERVES variable includes the ending balances for the LIFO, inventory and accounts receivable reserves. Reductions in these accounts relative to the underlying rate of growth in the business may indicate that the company is postponing current expenses for future periods, gradually making expectations more challenging to achieve. In a single year or on their own, such a movement might not say anything, but combined with other signals, may be significant.</p>
<table>
<colgroup>
<col width="21%" />
<col width="34%" />
<col width="43%" />
</colgroup>
<thead>
<tr class="header">
<th>Torpedo</th>
<th>NC Ticker</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Accruals/Sales</td>
<td>RESERVES_YOY_DELTA_PER_REVENUE</td>
<td>Reserves/Revenues</td>
</tr>
<tr class="even">
<td>Accruals vs. Sales</td>
<td>None</td>
<td>Unsure what of diff with Accruals/Sales</td>
</tr>
<tr class="odd">
<td>None</td>
<td>RESERVES_PERCENT_IMPACT</td>
<td>Reserves divided by Net Assets</td>
</tr>
</tbody>
</table>
</div>
<div id="earnings-quality-earnings-quality" class="section level3">
<h3>Earnings Quality (Earnings Quality)</h3>
<p>NC takes pains to <a href="https://www.newconstructs.com/education/accounting-loopholes/">adjust earnings</a> to remove items in the MD&amp;A and footnotes which are non-recurring (positive and negative), but have been included in the main financial statements. NC also adds items which affect earnings, which have been excluded in order to derive its <a href="https://www.newconstructs.com/core-earnings-earnings-distortion-explanation-examples/">CORE_EARNINGS_AFTER_TAX</a>. It then derives <a href="https://www.newconstructs.com/core-earnings-earnings-distortion-explanation-examples/">EARNINGS_DISTORTION</a> based on the difference between the derived Core Earnings and the GAAP Net Earnings. We would use the EARNINGS_DISTORTION as a percentage of net income and net assets as indicators of earnings quality, and likely a superior proxy to Mr. Gulliver’s measurements. Thorough adjustments such as these are the main challenge, and we doubt there would be a more thorough and comprehensive data set for this purpose than that of NC.</p>
<table>
<colgroup>
<col width="16%" />
<col width="49%" />
<col width="34%" />
</colgroup>
<thead>
<tr class="header">
<th>Torpedo</th>
<th>NC Ticker</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Net Income</td>
<td>None</td>
<td>Skip</td>
</tr>
<tr class="even">
<td>Adj Income</td>
<td>None</td>
<td>Skip</td>
</tr>
<tr class="odd">
<td>Core Income</td>
<td>None</td>
<td>Skip</td>
</tr>
<tr class="even">
<td>None</td>
<td>EARNINGS_DISTORTION_TOTAL_PER_ASSETS</td>
<td>Divides Net Inc by Core Inc</td>
</tr>
<tr class="odd">
<td>None</td>
<td>EARNINGS_DISTORTION_TOTAL_PER_INCOME_NET</td>
<td>Divides Net Inc by Core Inc</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="efficiency" class="section level2">
<h2>EFFICIENCY</h2>
<div id="returns-efficiency" class="section level3">
<h3>Returns (Efficiency)</h3>
<p>Mr. Gulliver used ROE and ROA in addition to ROIC and CF ROI as measures of returns, but these are again derived from reported GAAP net income. NC makes the case against using reported ROE in <a href="%5B%3Chttps://www.newconstructs.com/dont-get-misled-by-return-on-equity-roe%3E">Don’t Get Misled about Return on Equity (ROE)</a>](<a href="https://www.newconstructs.com/dont-get-misled-by-return-on-equity-roe/" class="uri">https://www.newconstructs.com/dont-get-misled-by-return-on-equity-roe/</a>), so we would rely on NC’s metrics (as built into its ROIC and Invested Capital). NC charges companies for past write-offs, by adding back to Shareholder’s Equity (so management has to carry the full weight of past missteps and can’t hide behind “serial charges”). In the case of NC’s RATING_ROIC, returns relative to Invested Capital are bundled into five categories from relatively low to high. According to NC’s methodology, <a href="https://www.newconstructs.com/education/education-close-the-loopholes/education-economic-earnings/">ECONOMIC_PROFIT</a> is the amount of ROIC in excess of WACC times Invested Capital as a hurdle rate or charge for use of the capital during the period. As for Free Cash Flow, NC explains their metric in <a href="https://www.newconstructs.com/education-free-cash-flow/">Free Cash Flow And FCF Yield</a>. For our purposes, we would use the Free Cash Flow per Invested Capital. Because NC doesn’t provide a Free Cash Flow Yield rating, we might construct an index for the companies in that industry during the period and cut them into five categories according to SIC (Industry) code. The beauty of working with R is that we can quickly iterate and reshape variables in any form we would like once we have the data in our environment.</p>
<table>
<colgroup>
<col width="11%" />
<col width="43%" />
<col width="44%" />
</colgroup>
<thead>
<tr class="header">
<th>Torpedo</th>
<th>NC Ticker</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ROE/ROA</td>
<td>None</td>
<td>Skip</td>
</tr>
<tr class="even">
<td>ROIC</td>
<td>RATING_ROIC</td>
<td>NC rating version grades ROIC level</td>
</tr>
<tr class="odd">
<td>None</td>
<td>RATING_INCOME_NET_ECONOMIC_PROFIT</td>
<td>Economic EPS vs Reported Ranking</td>
</tr>
<tr class="even">
<td>CF ROI</td>
<td>FREE_CASH_FLOW_PER_CAPITAL_INVESTED</td>
<td>NC version measuring Cash Generation</td>
</tr>
</tbody>
</table>
</div>
<div id="margins-return-trends-efficiency" class="section level3">
<h3>Margins &amp; Return Trends (Efficiency)</h3>
<p>This category is distinguished from Returns above in that we would consider using the 3-year weighted trend with growing penalties for ongoing negative variance (instead of the absolute level of returns relative to peer companies). It is easy to understand that negative incremental changes in margins and returns on capital could be an early indication of deteriorating operating or business conditions. For example, declining gross margins might indicate a weakening competitive position, and higher overhead costs through increased SG&amp;A could pressure EBIT margins. NOPAT might reflect increased tax rates, and ROIC that the company might be effectively buying more business. Since we are looking for combinations of factors across many metrics, we are able to spread our net widely to capture any possible signal of deteriorating business conditions for an enterprise and allow a seemingly small change in one margin might interact with another in the cash flow, balance sheet or earnings quality metrics.</p>
<table>
<colgroup>
<col width="18%" />
<col width="42%" />
<col width="39%" />
</colgroup>
<thead>
<tr class="header">
<th>Torpedo</th>
<th>NC Ticker</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Gross Margin</td>
<td>PROFIT_GROSS_PER_REVENUE</td>
<td>Calculate weighted 3 yr Trend</td>
</tr>
<tr class="even">
<td>EBIT Margin</td>
<td>EBIT</td>
<td>Calculate weighted 3 yr Trend</td>
</tr>
<tr class="odd">
<td>EBIT Margin</td>
<td>REVENUE</td>
<td></td>
</tr>
<tr class="even">
<td>SG&amp;A Margin</td>
<td>EXPENSES_SGA</td>
<td>SG&amp;A / Revenue</td>
</tr>
<tr class="odd">
<td>SG&amp;A Margin</td>
<td>REVENUE</td>
<td>Calculate weighted 3 yr Trend</td>
</tr>
<tr class="even">
<td>None</td>
<td>RESEARCH_AND_DEVELOPMENT_EXPENSE</td>
<td>Calculate R&amp;D / Revenue</td>
</tr>
<tr class="odd">
<td>None</td>
<td>REVENUE</td>
<td>Calculate weighted 3 yr Trend</td>
</tr>
<tr class="even">
<td>NOPAT Margin</td>
<td>NOPAT</td>
<td>Calculate NOPAT /Revenue</td>
</tr>
<tr class="odd">
<td>NOPAT Margin</td>
<td>REVENUE</td>
<td>Calculate weighted 3 yr Trend</td>
</tr>
<tr class="even">
<td>ROIC</td>
<td>ROIC</td>
<td>Calculate weighted 3 yr Trend</td>
</tr>
<tr class="odd">
<td>Tax Rate</td>
<td>Skip</td>
<td>NOPAT margin seems sufficient</td>
</tr>
</tbody>
</table>
</div>
<div id="turnover-efficiency" class="section level3">
<h3>Turnover (Efficiency)</h3>
<p>Mr. Gulliver used the inventory and receivables 12-month turnover ratios as indicators of an efficiently run business, but we would use the full working capital efficiency given the available NC metric. This metric uses current assets minus non-interest bearing liabilities and is scrubbed of non-operating items. We might construct ranking groupings relative to other companies in the same industry (by SIC) as we did with the other efficiency metrics above. This is distinguished from the Inventory and Receivable days outstanding in the sense of being a one-year metric and with a ranking instead of a signal of change in operating conditions leading to inventory build-up or slow sell-through of products. He also uses reported Assets/Equity, so we would use NC’s fixed income EQUITY_MULTIPLIER, which is a reflection of Adjusted Assets over operating Shareholder’s Equity.</p>
<table>
<colgroup>
<col width="18%" />
<col width="50%" />
<col width="30%" />
</colgroup>
<thead>
<tr class="header">
<th>Torpedo</th>
<th>NC Ticker</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Asset/Equity</td>
<td>Unknown</td>
<td>Fixed income Equity Multiplier</td>
</tr>
<tr class="even">
<td>Receivables 12 mo</td>
<td>CAPITAL_WORKING_NET_TURNS</td>
<td>Combine</td>
</tr>
<tr class="odd">
<td>Inventory 12 mo</td>
<td>CAPITAL_WORKING_NET_TURNS</td>
<td>Combine</td>
</tr>
<tr class="even">
<td>None</td>
<td>CASH_CONVERSION_CYCLE</td>
<td></td>
</tr>
<tr class="odd">
<td>None</td>
<td>CAPITAL_WORKING_NET_YOY_DELTA_PER_REVENUE_YOY_DELTA</td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="liquidity" class="section level2">
<h2>LIQUIDITY</h2>
<div id="liquidity-fixed-income-data-set" class="section level3">
<h3>Liquidity (Fixed income data set)</h3>
<p>After all that work to clean up the financial reports, why not also construct <a href="https://www.newconstructs.com/education-fixed-income/">fixed income ratings</a>, which is exactly what NC did. Mr. Gulliver uses current ratio and quick ratio, so we would use the same as they are already available in the NC fixed income database and likely not needing adjustment. NC itself uses the 3-yr average FCF-to-Debt and EBITDA-to-Debt as its liquidity proxies, so we would use the available DEBT_NET_OF_CASH_PER_EBITDA and calculate EBITDA-to-Debt using NC’s DEBT_FINANCING and the adjusted EBITDA. NC has a really interesting metric (EXCESS_CASH), which is the cash retained, but not needed to maintain operations. It seems like changes in this especially around zero might offer information. It is entirely possible that a company in a tight liquidity situation might offload inventory at lower prices to the detriment of margins or start to obtain less favorable terms from suppliers.</p>
<table>
<colgroup>
<col width="17%" />
<col width="33%" />
<col width="48%" />
</colgroup>
<thead>
<tr class="header">
<th>Torpedo</th>
<th>NC Ticker</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Current Ratio</td>
<td>Unknown</td>
<td>Fixed Income data set</td>
</tr>
<tr class="even">
<td>Quick Ratio</td>
<td>Unknown</td>
<td>Fixed Income data set</td>
</tr>
<tr class="odd">
<td>Cash</td>
<td>EXCESS_CASH</td>
<td>Calculate Debt - Excess Cash/3-yr avg FCF</td>
</tr>
<tr class="even">
<td>None</td>
<td>DEBT_FINANCING</td>
<td>NC Total Debt</td>
</tr>
<tr class="odd">
<td>None</td>
<td>EBITDA</td>
<td>NC Adjusted EBITDA</td>
</tr>
<tr class="even">
<td>None</td>
<td>DEBT_NET_OF_CASH_PER_EBITDA</td>
<td>NC Liquidity measure</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="valuation" class="section level2">
<h2>VALUATION</h2>
<div id="valuation-1" class="section level3">
<h3>Valuation</h3>
<p>Valuation was not part of Mr. Gulliver’s CFA Revelations paper, but he understandably used one for work with his firm in order to make investment decisions. Obviously, a highly valued stock which missed expectations would have more downside. NC has spent more than a little time explaining why traditional metrics like P/E, P/Cash, P/Sales and PEG ratios are poor indicators of stock performance in <a href="https://www.newconstructs.com/education/basic-metrics/">Basic Metrics</a>. Without going into great detail, NC found a more robust link between EV/IC and their adjusted ROIC than any of these other metrics, so we would use these.</p>
<table style="width:99%;">
<colgroup>
<col width="18%" />
<col width="44%" />
<col width="36%" />
</colgroup>
<thead>
<tr class="header">
<th>Torpedo</th>
<th>NC Ticker</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>P/E</td>
<td>Skip</td>
<td>NC version seems better</td>
</tr>
<tr class="even">
<td>P/Cash</td>
<td>Skip</td>
<td>NC version seems better</td>
</tr>
<tr class="odd">
<td>P/Sales</td>
<td>Skip</td>
<td>NC version seems better</td>
</tr>
<tr class="even">
<td>P/Growth</td>
<td>Skip</td>
<td>NC version seems better</td>
</tr>
<tr class="odd">
<td>None</td>
<td>CAPITAL_INVESTED</td>
<td>EV/IC</td>
</tr>
<tr class="even">
<td>None</td>
<td>ENTERPRISE_VALUE</td>
<td></td>
</tr>
<tr class="odd">
<td>None</td>
<td>RATING_GAP</td>
<td>Proxy for PEG</td>
</tr>
<tr class="even">
<td>None</td>
<td>RATING_PRICE_TO_EBV_RATIO</td>
<td>Proxy for P/Book</td>
</tr>
<tr class="odd">
<td>None</td>
<td>RATING_FCF_YIELD</td>
<td>Proxy for P/Cash</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="other-orthogonal-factors" class="section level2">
<h2>OTHER ORTHOGONAL FACTORS</h2>
<p><em>Revelations</em> also did not discuss potential orthogonal factors directly, but a change in the Auditor, changes in significant accounting policies or a qualified opinion are fields in the NC database which might be risk factors. Frequent amendments are certainly a risk factor, but NC do not keep track of past filing changes. Natural language processing could be used to assess changes in tone by the management in the MD&amp;A. Factors for executive compensation alignment might be added, and indeed NC does have a ranking for this in its data. Aggressive accounting might be more prevalent depending on industry. For the purposes of this exercise, we would need to remove cases where the filing has already been amended as the underlying problem would already have been discovered and no longer a risk factor. Other future addition would be to include the short interest ratio and insider selling metrics. Data such as these could be easily added to the analysis with R, so that is a future opportunity.</p>
<table>
<thead>
<tr class="header">
<th>Torpedo</th>
<th>Ticker</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>None</td>
<td>Unknown</td>
<td>Auditor</td>
</tr>
<tr class="even">
<td>None</td>
<td>Unknown</td>
<td>Auditor Opinion</td>
</tr>
<tr class="odd">
<td>None</td>
<td>Unknown</td>
<td>CEO name</td>
</tr>
<tr class="even">
<td>None</td>
<td>Unknown</td>
<td>CFO name</td>
</tr>
<tr class="odd">
<td>None</td>
<td>Unknown</td>
<td>SIC code</td>
</tr>
<tr class="even">
<td>None</td>
<td>Unknown</td>
<td>filing type (ie: 10-K, 10-K/A)</td>
</tr>
<tr class="odd">
<td>None</td>
<td>Unknown</td>
<td>Report date</td>
</tr>
<tr class="even">
<td>None</td>
<td>Unknown</td>
<td>Filing date</td>
</tr>
<tr class="odd">
<td>None</td>
<td>None</td>
<td>Restatements</td>
</tr>
<tr class="even">
<td>None</td>
<td>None</td>
<td>Management Incentives</td>
</tr>
<tr class="odd">
<td>None</td>
<td>None</td>
<td>Short Interest</td>
</tr>
<tr class="even">
<td>None</td>
<td>None</td>
<td>SEC Insider Selling Metrics</td>
</tr>
<tr class="odd">
<td>None</td>
<td>None</td>
<td>Dividend coverage</td>
</tr>
<tr class="even">
<td>None</td>
<td>None</td>
<td>Stock Price on reporting date</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>In the old days, we used Datastream and then Bloomberg to look for insight in financial data, so it is surprising that such a data rich field as financial analysis feels to us like it stalled out compared to our rich new world of advanced analytics. The main potential sponsors, like the SEC, CFA Institute and AICPA, don’t seem unaware or to have fallen behind in adopting the habits of the free and open source data movements. The opportunity to look at all core earnings from all of the companies in one data set, and to iterate over it in search of revealing patterns, is an exciting prospect, and we have written several posts to try to get there. We read Mr. Gulliver’s piece in 2003 when there was no R or Python, no way to get data in that form and building something like that was unimaginable. Now it feels like it could take a few weeks to build something really exceptional, tease out some real signals and maybe cause a management inclined to push the envelope to think twice. If any readers are aware of research or data available along these lines, we would appreciate knowing.</p>
</div>
